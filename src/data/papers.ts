import { Paper } from '@/types/paper';

export const papers: Paper[] = [
  // DeepSeek Papers
  {
    id: 'deepseek-r1',
    title: 'DeepSeek-R1',
    titleKo: '추론의 민주화와 GRPO',
    organization: 'DeepSeek',
    date: '2025-01',
    arxivUrl: 'https://arxiv.org/abs/2501.12948',
    githubUrl: 'https://github.com/deepseek-ai/DeepSeek-R1',
    summary: '오픈소스 모델이 OpenAI o1과 대등한 추론 능력을 갖추게 된 방법론',
    keyInnovation: 'GRPO (Group Relative Policy Optimization) - 비판 모델 없이 강화학습을 가능하게 하여 학습 비용을 획기적으로 절감',
    practicalInsight: '671B 모델의 추론 능력을 7B, 14B 소형 모델에 증류(Distillation) 성공. 인하우스 에이전트에 거대 모델 없이 복잡한 로직 처리 가능',
    domains: ['LLM', 'Reasoning'],
    tags: ['grpo', 'rlhf', 'distillation', 'open-source', 'cost-efficient'],
  },
  {
    id: 'deepseek-mhc',
    title: 'mHC (Manifold-Constrained Hyper-Connections)',
    titleKo: '매니폴드 제약 하이퍼 연결',
    organization: 'DeepSeek',
    date: '2026-01',
    arxivUrl: 'https://arxiv.org/abs/2601.03321',
    summary: '딥러닝 모델의 신호 발산/소실 문제를 해결하는 새로운 아키텍처',
    keyInnovation: '매니폴드(Manifold) 제약이 있는 하이퍼 연결 구조로 깊은 신경망의 안정적 학습 가능',
    practicalInsight: 'DeepSeek-V4의 기반 기술 예상. 제한된 하드웨어 환경에서 더 깊고 정교한 신경망 학습 가능',
    domains: ['LLM', 'Efficiency'],
    tags: ['architecture', 'training-stability', 'next-gen'],
    buildUpon: ['deepseek-v3'],
  },
  {
    id: 'deepseek-v3.2',
    title: 'DeepSeek-V3.2 & DSA',
    titleKo: '희소 어텐션과 에이전트 성능 도약',
    organization: 'DeepSeek',
    date: '2025-12',
    arxivUrl: 'https://arxiv.org/abs/2412.19437',
    githubUrl: 'https://github.com/deepseek-ai/DeepSeek-V3',
    summary: 'V3의 마이너 업데이트, 에이전트 성능 측면에서 중요한 도약',
    keyInnovation: 'DSA (DeepSeek Sparse Attention) - 긴 컨텍스트 처리 시 계산 복잡도 대폭 절감',
    practicalInsight: 'SDD 환경에서 대규모 소스 코드 전체를 컨텍스트로 사용할 때 비용/속도 문제 해결',
    domains: ['LLM', 'Agent', 'Efficiency'],
    tags: ['sparse-attention', 'long-context', 'agent'],
    buildUpon: ['deepseek-r1'],
  },
  {
    id: 'deepseek-v4',
    title: 'DeepSeek-V4',
    titleKo: '차세대 코딩 전문 모델',
    organization: 'DeepSeek',
    date: '2026-02',
    summary: '코딩 및 장문 문맥 처리에 특화된 차세대 모델 (출시 예정)',
    keyInnovation: '멀티 파일 프로젝트 단위의 이해도 극대화, 모든 코딩 어시스턴트 압도',
    practicalInsight: 'SDD 워크플로우 A/B 테스트 후보. API 비용이 타사 대비 매우 저렴하여 운영 비용 절반 이하 절감 가능',
    domains: ['LLM', 'Agent'],
    tags: ['coding', 'multi-file', 'cost-efficient', 'upcoming'],
    buildUpon: ['deepseek-v3.2', 'deepseek-mhc'],
  },

  // DeepMind Papers - AI for Science
  {
    id: 'alphagenome',
    title: 'AlphaGenome',
    titleKo: '유전체 분석 AI',
    organization: 'DeepMind',
    date: '2026-01',
    arxivUrl: 'https://deepmind.google/discover/blog/alphagenome-a-new-model-for-understanding-the-human-genome/',
    summary: 'DNA 서열에서 질병의 유전적 요인을 식별하는 AI 도구',
    keyInnovation: '최대 100만 개 염기서열 동시 분석, 유전자 변이가 단백질 발현/질병에 미치는 영향 예측',
    practicalInsight: '개인 맞춤형 치료제 개발의 토대. 바이오/헬스케어 AI 진출 시 핵심 참고 자료',
    domains: ['Science', 'Healthcare'],
    tags: ['genomics', 'personalized-medicine', 'alphafold-successor'],
  },
  {
    id: 'neuralgcm',
    title: 'NeuralGCM',
    titleKo: '신경망 기상 예측 모델',
    organization: 'DeepMind',
    date: '2026-01',
    arxivUrl: 'https://arxiv.org/abs/2311.07222',
    githubUrl: 'https://github.com/google-research/neuralgcm',
    summary: '전통적 물리 시뮬레이션과 AI를 결합한 기상 예측 모델',
    keyInnovation: '기존 모델보다 훨씬 적은 컴퓨팅으로 장기 전 지구 강수량 및 기후 변화 정밀 예측',
    practicalInsight: '물리 시뮬레이션 + AI 하이브리드 접근법의 모범 사례',
    domains: ['Science'],
    tags: ['weather', 'physics-ai-hybrid', 'climate'],
  },
  {
    id: 'medgemma',
    title: 'MedGemma 1.5 & MedASR',
    titleKo: '의료 영상 및 음성 인식 모델',
    organization: 'DeepMind',
    date: '2026-01',
    arxivUrl: 'https://ai.google.dev/gemma/docs/medgemma',
    githubUrl: 'https://github.com/google/medical-imaging-research',
    summary: '의료 영상 해석 및 의료용 음성 인식 특화 모델',
    keyInnovation: '의료진 진단 보조, 복잡한 의학 용어 실시간 텍스트화',
    practicalInsight: '헬스케어 도메인 특화 모델의 벤치마크',
    domains: ['Healthcare', 'Multimodal'],
    tags: ['medical-imaging', 'speech-recognition', 'domain-specific'],
  },

  // DeepMind Papers - Multimodal & Video
  {
    id: 'd4rt',
    title: 'D4RT',
    titleKo: '4차원 장면 재구성 및 트래킹',
    organization: 'DeepMind',
    date: '2026-01',
    arxivUrl: 'https://arxiv.org/abs/2501.01320',
    summary: '4차원(공간 3D + 시간) 장면 재구성 및 트래킹 모델',
    keyInnovation: '평면 영상에서 물체의 입체적 움직임과 시간 흐름 동시 파악, 기존 대비 300배 빠른 픽셀 단위 추적',
    practicalInsight: '로봇과 AR 분야의 핵심 기술. 실시간 공간 인식 시스템 구축 시 필수 참고',
    domains: ['Vision', 'Robotics', 'Multimodal'],
    tags: ['4d-reconstruction', 'tracking', 'ar', 'robotics'],
  },
  {
    id: 'veo-3.1',
    title: 'Veo 3.1',
    titleKo: '고품질 영상 생성 모델',
    organization: 'DeepMind',
    date: '2026-01',
    arxivUrl: 'https://deepmind.google/technologies/veo/',
    summary: '일관성과 물리적 법칙 준수 능력이 향상된 영상 생성 모델',
    keyInnovation: '성분 기반 영상 생성(Ingredients to Video) 기능으로 사용자 의도 정밀 반영',
    practicalInsight: '영상 생성 AI 도입 검토 시 품질 벤치마크',
    domains: ['Vision', 'Multimodal'],
    tags: ['video-generation', 'consistency', 'physics-aware'],
  },
  {
    id: 'trecvit',
    title: 'TRecViT',
    titleKo: '순환 비디오 트랜스포머',
    organization: 'DeepMind',
    date: '2026-01',
    arxivUrl: 'https://arxiv.org/abs/2501.02125',
    summary: '순환 신경망 구조를 결합한 비디오 트랜스포머',
    keyInnovation: 'Recurrent 구조로 긴 비디오 컨텍스트 효율적 처리',
    practicalInsight: '장시간 비디오 분석이 필요한 서비스에 적용 가능',
    domains: ['Vision', 'Efficiency'],
    tags: ['video-transformer', 'recurrent', 'long-video'],
  },

  // DeepMind Papers - Foundation Models & Agents
  {
    id: 'atlas',
    title: 'ATLAS',
    titleKo: '다국어 모델 스케일링 법칙',
    organization: 'DeepMind',
    date: '2026-01',
    arxivUrl: 'https://arxiv.org/abs/2501.16777',
    summary: '다국어 모델을 위한 실질적인 스케일링 법칙 제시',
    keyInnovation: '다양한 언어 데이터를 가장 효율적으로 학습시키는 최적의 파라미터 비율 정의',
    practicalInsight: '글로벌 서비스 개발 시 어떤 언어 데이터에 리소스를 집중할지 데이터 전략 수립에 활용',
    domains: ['LLM', 'Efficiency'],
    tags: ['multilingual', 'scaling-laws', 'data-strategy'],
  },
  {
    id: 'alphaevolve',
    title: 'AlphaEvolve',
    titleKo: '자율 알고리즘 발견 에이전트',
    organization: 'DeepMind',
    date: '2025-06',
    arxivUrl: 'https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/',
    summary: 'Gemini 기반 알고리즘 자동 최적화/생성 에이전트',
    keyInnovation: '수학적 난제 해결, 코딩 효율 극대화 코드 직접 작성. 구글 데이터센터 스케줄링 알고리즘 실제 개선',
    practicalInsight: 'AI가 서비스 코어 로직을 어떻게 최적화할 수 있는지에 대한 실무적 답변',
    domains: ['Agent', 'Reasoning'],
    tags: ['code-optimization', 'algorithm-discovery', 'evolutionary'],
  },
  {
    id: 'gemini-3',
    title: 'Gemini 3 Pro',
    titleKo: '제미나이 3 프로',
    organization: 'DeepMind',
    date: '2025-12',
    arxivUrl: 'https://arxiv.org/abs/2403.05530',
    summary: '딥마인드 최신 플래그십 모델, 추론 능력 비약적 향상',
    keyInnovation: 'SWE-bench 76.2% 달성. Deep Think 모드와 Flash 모델 이원화',
    practicalInsight: '파운데이션 모델 선택 시 Deep Think vs Flash 성능/비용 트레이드오프 판단 기준',
    domains: ['LLM', 'Reasoning', 'Agent'],
    tags: ['flagship', 'swe-bench', 'reasoning'],
  },

  // DeepMind Papers - Robotics
  {
    id: 'gemini-robotics',
    title: 'Gemini Robotics 2026',
    titleKo: '제미나이 로보틱스',
    organization: 'DeepMind',
    date: '2026-01',
    arxivUrl: 'https://deepmind.google/discover/blog/gemini-robotics-unlocking-reasoning-for-physical-ai/',
    summary: 'Gemini 멀티모달 능력을 로봇 제어에 통합',
    keyInnovation: '복잡한 자연어 명령을 시각 정보와 결합해 물리적 행동으로 전환',
    practicalInsight: '로봇 + LLM 통합 아키텍처의 참조 모델',
    domains: ['Robotics', 'Multimodal', 'Agent'],
    tags: ['embodied-ai', 'natural-language-control', 'multimodal'],
  },
  {
    id: 'sima-2',
    title: 'SIMA 2',
    titleKo: '협력형 게임 에이전트',
    organization: 'DeepMind',
    date: '2025-11',
    arxivUrl: 'https://arxiv.org/abs/2404.10179',
    summary: '3D 가상 세계에서 인간과 협력하며 학습하는 에이전트',
    keyInnovation: '승리 목적이 아닌 인간 지시 이해와 협력 능력 테스트',
    practicalInsight: '인간-AI 협업 인터페이스 설계 시 참고',
    domains: ['Agent', 'Robotics'],
    tags: ['game-agent', 'human-ai-collaboration', 'instruction-following'],
  },

  // DeepMind Papers - Agent & RAG
  {
    id: 'agent-scaling-laws',
    title: 'Towards a Science of Scaling Agent Systems',
    titleKo: '에이전트 시스템 확장의 과학',
    organization: 'DeepMind',
    date: '2026-01',
    arxivUrl: 'https://arxiv.org/abs/2501.16893',
    summary: '에이전트 시스템 확장 시 성능 향상/저하 조건을 정량 분석한 최초의 논문',
    keyInnovation: '에이전트 숫자 증가가 항상 좋은 것이 아님을 증명. 병렬/순차 작업 구분 가이드라인 제시',
    practicalInsight: '멀티 에이전트 워크플로우 도입 시 아키텍처 설계의 기술적 근거',
    domains: ['Agent', 'Efficiency'],
    tags: ['multi-agent', 'scaling-laws', 'orchestration', 'must-read'],
  },
  {
    id: 'speculative-rag',
    title: 'Speculative RAG',
    titleKo: '추측적 RAG',
    organization: 'DeepMind',
    date: '2024-01',
    arxivUrl: 'https://arxiv.org/abs/2407.08223',
    summary: '작은 모델이 초안 작성, 큰 모델이 검증하는 RAG 방식',
    keyInnovation: 'RAG 지연 시간 51% 이상 감소하면서 정확도 향상',
    practicalInsight: '엔터프라이즈 챗봇 UX 개선 및 비용 효율화 전략의 핵심 참고 자료',
    domains: ['RAG', 'Efficiency'],
    tags: ['latency-reduction', 'draft-verify', 'enterprise'],
  },
  {
    id: 'graphrag',
    title: 'GraphRAG',
    titleKo: '그래프 기반 RAG',
    organization: 'Microsoft',
    date: '2025-08',
    arxivUrl: 'https://arxiv.org/abs/2404.16130',
    githubUrl: 'https://github.com/microsoft/graphrag',
    summary: '벡터 유사도 검색의 한계를 지적하고 Knowledge Graph 결합',
    keyInnovation: '관계형 지식을 활용한 검색으로 복잡한 쿼리 처리 능력 향상',
    practicalInsight: '복잡한 비즈니스 로직이나 문서 간 관계 파악이 필요한 시스템에 적용',
    domains: ['RAG', 'LLM'],
    tags: ['knowledge-graph', 'relational', 'complex-queries'],
  },

  // Auto-added: 2026-01-29
  {
    id: 'ctrlcot-dualgranularity-chainofthought-compression',
    title: 'CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning',
    titleKo: 'CtrlCoT: 제어 가능한 추론을 위한 이중 세분성 사고 사슬 압축',
    organization: 'Alibaba',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20467v1',
    summary: 'CoT(사고 사슬) 프롬프트는 LLM 추론을 개선하지만 자세한 추적으로 인해 높은 대기 시간과 메모리 비용이 발생하므로 정확성이 보존된 CoT 압축이 활성화됩니다. 기존 방법은 종종 보수적인 의미론적 수준에서 CoT를 단축하거나 공격적으로 토큰을 잘라냅니다.',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["LLM", "Agent", "RAG"],
    tags: ["reasoning", "rag", "chain-of-thought", "cot", "alignment"],
  },
  {
    id: 'improving-diffusion-language-model',
    title: 'Improving Diffusion Language Model Decoding through Joint Search in Generation Order and Token Space',
    titleKo: '생성 순서 및 토큰 공간의 공동 검색을 통한 확산 언어 모델 디코딩 개선',
    organization: 'MIT',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20339v1',
    summary: 'DLM(확산 언어 모델)은 가능한 많은 디코딩 궤적을 탐색할 수 있는 순서에 구애받지 않는 생성을 제공합니다. 그러나 현재의 디코딩 방법은 단일 궤적을 사용하므로 궤적 공간 탐색이 제한됩니다. 우리는 공동 검색을 통해 이 공간을 탐색하기 위해 Order-Token Search를 도입합니다.',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Efficiency", "LLM", "Reasoning"],
    tags: ["reasoning", "grpo", "math", "benchmark", "efficient"],
  },
  {
    id: 'beyond-the-needles-illusion',
    title: 'Beyond the Needle\'s Illusion: Decoupled Evaluation of Evidence Access and Use under Semantic Interference at 326M-Token Scale',
    organization: 'Meta',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20276v1',
    summary: '장기 컨텍스트 LLM 에이전트는 대규모 환경에서 올바른 증거에 액세스하고 이를 충실하게 사용해야 합니다. 그러나 인기 있는 NIAH(Needle-in-a-Haystack) 평가는 대부분 양성 범위 위치를 측정합니다. 바늘은 거의 독특하며 건초 더미는 거의 관련이 없습니다. EverMemBench-S를 소개합니다(...',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["LLM", "RAG", "Reasoning"],
    tags: ["agent", "long-context", "rag", "retrieval", "benchmark"],
  },
  {
    id: 'policy-of-thoughts-scaling',
    title: 'Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution',
    titleKo: '생각의 정책: 테스트 시간 정책 진화를 통한 LLM 추론 확장',
    organization: 'DeepSeek',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20379v1',
    summary: 'LLM(대형 언어 모델)은 동결된 정책 가정으로 인한 불안정성으로 인해 복잡하고 장기적인 추론에 어려움을 겪고 있습니다. 현재 테스트 시간 확장 방법은 실행 피드백을 개선하기 위해 내부화하지 않고 궤적을 필터링하거나 다시 작성하기 위한 외부 신호로만 처리합니다.',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Efficiency", "Reasoning", "Agent"],
    tags: ["reasoning", "grpo", "efficient"],
  },
  {
    id: 'deepseekocr-2-visual-causal',
    title: 'DeepSeek-OCR 2: Visual Causal Flow',
    titleKo: 'DeepSeek-OCR 2: 시각적 인과 흐름',
    organization: 'DeepSeek',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20552v1',
    summary: '우리는 이미지 의미론에 따라 시각적 토큰을 동적으로 재정렬할 수 있는 새로운 인코더인 DeepEncoder V2의 타당성을 조사하기 위해 DeepSeek-OCR 2를 제시합니다. 기존의 비전 언어 모델(VLM)은 항상 고정 래스터 스캔 순서(왼쪽 위에서 오른쪽 아래로)로 시각적 토큰을 처리합니다.',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Vision", "Reasoning"],
    tags: ["reasoning", "vision-language"],
  },
  {
    id: 'less-is-more-benchmarking',
    title: 'Less is More: Benchmarking LLM Based Recommendation Agents',
    titleKo: '적을수록 좋다: LLM 기반 추천 에이전트 벤치마킹',
    organization: 'DeepSeek',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20316v1',
    summary: '개인화된 제품 추천을 위해 LLM(대형 언어 모델)이 점점 더 많이 배포되고 있으며, 실무자들은 일반적으로 사용자 구매 기록이 길수록 더 나은 예측이 가능하다고 가정합니다. 우리는 4개의 최신 LLM GPT-4o-mini에 대한 체계적인 벤치마크를 통해 이 가정에 도전합니다.',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Efficiency", "LLM", "Agent"],
    tags: ["agent", "benchmark"],
  },
  {
    id: 'one-word-is-enough',
    title: 'One Word is Enough: Minimal Adversarial Perturbations for Neural Text Ranking',
    titleKo: '한 단어로 충분합니다: 신경 텍스트 순위 지정을 위한 최소한의 적대적 교란',
    organization: 'Meta',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20283v1',
    summary: '신경 순위 모델(NRM)은 강력한 검색 효율성을 달성하지만 이전 연구에서는 적대적 교란에 취약한 것으로 나타났습니다. 우리는 의미론적으로 단일 항목을 삽입하거나 대체하여 대상 문서를 승격시키는 최소한의 쿼리 인식 공격으로 이 견고성 질문을 다시 검토합니다.',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Efficiency", "LLM", "RAG"],
    tags: ["rag", "retrieval"],
  },
  {
    id: 'empirical-likelihoodbased-fairness-auditing',
    title: 'Empirical Likelihood-Based Fairness Auditing: Distribution-Free Certification and Flagging',
    titleKo: '경험적 가능성 기반 공정성 감사: 무배포 인증 및 플래그 지정',
    organization: 'Meta',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20269v1',
    summary: '재범 예측 및 자동화된 인력 선택과 같은 고위험 애플리케이션의 기계 학습 모델은 종종 민감한 하위 집단 간에 체계적인 성능 차이를 나타내어 알고리즘 편향에 대한 심각한 우려를 불러일으킵니다. 공정성 감사는 다음을 통해 이러한 위험을 해결합니다.',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Efficiency", "LLM", "RAG"],
    tags: ["rag", "efficient"],
  },
  {
    id: 'inequality-in-congestion-games',
    title: 'Inequality in Congestion Games with Learning Agents',
    titleKo: '학습 에이전트를 사용한 혼잡 게임의 불평등',
    organization: 'Meta',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20578v1',
    summary: '교통망 확대로 누가 혜택을 받나요? 이러한 개입은 이동성을 개선하기 위해 고안되었지만 불평등을 야기할 수도 있습니다. 본 논문에서는 네트워크 자체의 구조뿐만 아니라 통근자들이 네트워크에 적응하는 방식의 차이에서도 차이가 발생한다는 점을 보여줍니다. 우리는 통근자를 모델로 삼고 있습니다...',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Reasoning", "Agent"],
    tags: ["agent"],
  },
  {
    id: 'fair-recourse-for-all',
    title: 'Fair Recourse for All: Ensuring Individual and Group Fairness in Counterfactual Explanations',
    titleKo: '모두를 위한 공정한 의지: 반사실적 설명에서 개인 및 그룹의 공정성 보장',
    organization: 'Meta',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20449v1',
    summary: '설명 가능한 인공 지능(XAI)은 기계 학습(ML) 모델의 투명성을 향상시키는 데 점점 더 중요해지고 있습니다. 다양한 XAI 기술 중에서 반사실적 설명(CF)은 입력 특성의 변화가 어떻게 변경될 수 있는지 설명하는 능력으로 인해 중추적인 역할을 합니다.',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Efficiency", "LLM", "Reasoning"],
    tags: ["benchmark"],
  },

  // Auto-added: 2026-01-29
  {
    id: 'beyond-speedup-utilizing-kv',
    title: 'Beyond Speedup -- Utilizing KV Cache for Sampling and Reasoning',
    titleKo: '속도 향상을 넘어서 - 샘플링 및 추론을 위해 KV 캐시 활용',
    organization: 'DeepSeek',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20326v1',
    summary: '일반적으로 자동 회귀 디코딩 속도를 높이는 데만 사용되는 KV 캐시는 추가 비용 없이 다운스트림 작업에 재사용할 수 있는 상황 정보를 인코딩합니다. 우리는 KV 캐시를 경량 표현으로 처리하여 전체 숨겨진 상태를 다시 계산하거나 저장할 필요가 없도록 제안합니다. W임에도 불구하고',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Agent", "Reasoning", "Efficiency"],
    tags: ["reasoning"],
  },
  {
    id: 'structurally-human-semantically-biased',
    title: 'Structurally Human, Semantically Biased: Detecting LLM-Generated References with Embeddings and GNNs',
    titleKo: '구조적으로 인간적이고 의미적으로 편향된: 임베딩 및 GNN을 사용하여 LLM 생성 참조 감지',
    organization: 'OpenAI',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20704v1',
    summary: '참고문헌 목록을 관리하는 데 대규모 언어 모델이 점점 더 많이 사용되면서 다음과 같은 의문이 제기됩니다. 참조 목록이 사람의 참조 목록과 구별될 수 있습니까? 우리는 10,000개의 초점 논문($\about$ 275,000 참조)에 대해 쌍을 이루는 인용 그래프, Ground Truth 및 GPT-4o 생성(파라메트릭 지식을 통해)을 구축합니다.',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Efficiency", "LLM"],
    tags: [],
  },

  // Auto-added: 2026-01-29
  {
    id: 'c3box-a-clipbased-classincremental',
    title: 'C3Box: A CLIP-based Class-Incremental Learning Toolbox',
    titleKo: 'C3Box: CLIP 기반 클래스 증분 학습 도구 상자',
    organization: 'Meta',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20852v1',
    summary: '전통적인 기계 학습 시스템은 일반적으로 진화하는 데이터 스트림에서 학습할 때 치명적인 망각이 발생하는 정적 데이터 분포를 위해 설계되었습니다. CIL(클래스 증분 학습)은 학습 시스템이 새로운 클래스를 지속적으로 학습하면서 동시에 학습할 수 있도록 하여 이러한 문제를 해결합니다.',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Vision", "Efficiency", "RAG"],
    tags: ["rag", "alignment", "benchmark"],
  },
  {
    id: 'fairt2v-trainingfree-debiasing-for',
    title: 'FAIRT2V: Training-Free Debiasing for Text-to-Video Diffusion Models',
    titleKo: 'FAIRT2V: 텍스트-비디오 확산 모델을 위한 훈련이 필요 없는 디바이어스',
    organization: 'Meta',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20791v1',
    summary: 'T2V(텍스트-비디오) 확산 모델은 급속한 발전을 이루었지만 인구통계학적 편견, 특히 성별 편견은 아직 대부분 탐구되지 않은 상태로 남아 있습니다. 우리는 미세 조정 없이 인코더로 인한 편향을 완화하는 텍스트-비디오 생성을 위한 훈련이 필요 없는 편향성 제거 프레임워크인 FairT2V를 제시합니다. 우리가 먼저',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Vision", "Reasoning", "Agent"],
    tags: ["reasoning", "video-generation", "diffusion-model"],
  },
  {
    id: 'a-new-dataset-and',
    title: 'A New Dataset and Framework for Robust Road Surface Classification via Camera-IMU Fusion',
    titleKo: '카메라-IMU 융합을 통한 강력한 도로 ​​표면 분류를 위한 새로운 데이터 세트 및 프레임워크',
    organization: 'MIT',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20847v1',
    summary: '도로 표면 분류(RSC)는 환경을 인식하는 예측 유지 관리 시스템의 핵심 요소입니다. 그러나 기존 RSC 기술은 제한된 감지 방식과 환경 다양성이 부족한 데이터 세트로 인해 좁은 작동 조건을 넘어서 일반화하는 데 실패하는 경우가 많습니다. 이 직장 주소',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Vision", "Multimodal", "Reasoning"],
    tags: ["multimodal", "benchmark"],
  },
  {
    id: 'posttraining-fairness-control-a',
    title: 'Post-Training Fairness Control: A Single-Train Framework for Dynamic Fairness in Recommendation',
    titleKo: '훈련 후 공정성 제어: 추천의 동적 공정성을 위한 단일 훈련 프레임워크',
    organization: 'Meta',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20848v1',
    summary: '추천 시스템의 불공평성을 완화하려는 노력이 커지고 있음에도 불구하고 기존 공정성 인식 방법은 일반적으로 훈련 시간에 공정성 요구 사항을 수정하고 제한된 훈련 후 유연성을 제공합니다. 그러나 실제 시나리오에서는 다양한 이해관계자가 서로 다른 공정성 요구 사항을 요구할 수 있습니다.',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["Reasoning", "Efficiency", "Agent"],
    tags: [],
  },
  {
    id: 'structured-semantic-information-helps',
    title: 'Structured Semantic Information Helps Retrieve Better Examples for In-Context Learning in Few-Shot Relation Extraction',
    titleKo: '구조화된 의미 정보는 Few-Shot 관계 추출에서 상황 내 학습을 위한 더 나은 예를 검색하는 데 도움이 됩니다.',
    organization: 'Alibaba',
    date: '2026-01',
    arxivUrl: 'http://arxiv.org/abs/2601.20803v1',
    summary: '본 논문에서는 원샷 관계 추출의 상황 내 학습을 위한 추가 예제를 자동으로 얻기 위한 몇 가지 전략을 제시합니다. 구체적으로, 우리는 기본 구문 세마의 유사성을 기반으로 새로운 예제를 선택하는 예제 선택을 위한 새로운 전략을 소개합니다.',
    keyInnovation: '',
    practicalInsight: '',
    domains: ["LLM"],
    tags: [],
  },



];

export function getPaperById(id: string): Paper | undefined {
  return papers.find(p => p.id === id);
}

export function getPapersByOrganization(org: string): Paper[] {
  return papers.filter(p => p.organization === org);
}

export function getPapersByDomain(domain: string): Paper[] {
  return papers.filter(p => p.domains.includes(domain as any));
}

export function getPapersByTag(tag: string): Paper[] {
  return papers.filter(p => p.tags.includes(tag));
}

export function getAllTags(): string[] {
  const tags = new Set<string>();
  papers.forEach(p => p.tags.forEach(t => tags.add(t)));
  return Array.from(tags).sort();
}

export function getAllDomains(): string[] {
  const domains = new Set<string>();
  papers.forEach(p => p.domains.forEach(d => domains.add(d)));
  return Array.from(domains).sort();
}
